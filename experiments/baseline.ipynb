{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from artemis.interactions_methods.model_agnostic import FriedmanHStatisticMethod, GreenwellMethod, SejongOhMethod\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from artemis.utilities.domain import InteractionMethod\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from artemis.additivity import AdditivityMeter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Y = B_1 * X_1 + B_2 * X2 + B_3 * X_3 + B_4 (X1 * X2) + \\epsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "lower = -5\n",
    "upper = 5\n",
    "\n",
    "betas = np.array([3, -7, 10, 2])\n",
    "\n",
    "X = pd.DataFrame(np.random.uniform(lower, upper, size=(N, 3)), columns=[\"x1\", \"x2\", \"x3\"])\n",
    "eps = np.random.uniform(size=(N,))\n",
    "y = X.apply(lambda row: np.dot(np.append(row, row[\"x1\"]*row[\"x2\"]), betas), axis=1)\n",
    "y = y + eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [(\"linear\", LinearRegression()), (\"random_forest\", RandomForestRegressor()), (\"neural_network\", MLPRegressor(hidden_layer_sizes=(5, 2), max_iter=30000))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name_model, model in models:\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 25%|██▌       | 1/4 [00:00<00:02,  1.39it/s]\u001B[A\n",
      " 50%|█████     | 2/4 [00:01<00:01,  1.48it/s]\u001B[A\n",
      " 75%|███████▌  | 3/4 [00:16<00:07,  7.41s/it]\u001B[A\n",
      "100%|██████████| 4/4 [00:17<00:00,  4.26s/it]\u001B[A\n",
      " 33%|███▎      | 1/3 [00:17<00:34, 17.06s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 25%|██▌       | 1/4 [00:00<00:02,  1.06it/s]\u001B[A\n",
      " 50%|█████     | 2/4 [00:01<00:01,  1.06it/s]\u001B[A\n",
      " 75%|███████▌  | 3/4 [00:25<00:11, 11.52s/it]\u001B[A\n",
      "100%|██████████| 4/4 [00:27<00:00,  6.95s/it]\u001B[A\n",
      " 67%|██████▋   | 2/3 [00:44<00:23, 23.39s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  1.60it/s]\u001B[A\n",
      " 50%|█████     | 2/4 [00:01<00:01,  1.67it/s]\u001B[A\n",
      " 75%|███████▌  | 3/4 [00:16<00:07,  7.08s/it]\u001B[A\n",
      "100%|██████████| 4/4 [00:16<00:00,  4.07s/it]\u001B[A\n",
      "100%|██████████| 3/3 [01:01<00:00, 20.39s/it]\n"
     ]
    }
   ],
   "source": [
    "result = list()\n",
    "methods_model_agnostic = [\n",
    "        (InteractionMethod.H_STATISTIC, FriedmanHStatisticMethod()),\n",
    "        (InteractionMethod.H_STATISTIC + \" NO_NORMALIZATION\", FriedmanHStatisticMethod(normalized=False)),\n",
    "        (InteractionMethod.VARIABLE_INTERACTION, GreenwellMethod()),\n",
    "        (InteractionMethod.PERFORMANCE_BASED, SejongOhMethod())\n",
    "]\n",
    "\n",
    "for name_model, model in tqdm(models):\n",
    "\n",
    "    for name_method, method in tqdm(methods_model_agnostic):\n",
    "\n",
    "        method_copy = copy(method)\n",
    "\n",
    "        if method_copy.method == InteractionMethod.PERFORMANCE_BASED:\n",
    "            method_copy.fit(model, X_train, y_true=y_train)\n",
    "        else:\n",
    "            method_copy.fit(model, X_train)\n",
    "\n",
    "        result.append({\"model\": name_model, \"method\": name_method, \"ovo\": method_copy.ovo})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame.from_records(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to its nature, linear model is unable to detect feature interactions.\n",
    "Therefore, as a sanity-check of interaction method correctness, we check if all methods have interaction values that are close to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 10**(-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Method: Friedman H-statistic Interaction Measure\n",
      "  Feature 1 Feature 2  is_below_threshold\n",
      "0        x1        x2                True\n",
      "1        x2        x3                True\n",
      "2        x1        x3                True\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Method: Friedman H-statistic Interaction Measure NO_NORMALIZATION\n",
      "  Feature 1 Feature 2  is_below_threshold\n",
      "0        x2        x3                True\n",
      "1        x1        x3                True\n",
      "2        x1        x2                True\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Method: Greenwell Variable Interaction Measure\n",
      "  Feature 1 Feature 2  is_below_threshold\n",
      "0        x2        x3                True\n",
      "1        x1        x2                True\n",
      "2        x1        x3                True\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Method: Sejong Oh Performance Based Interaction Measure\n",
      "  Feature 1 Feature 2  is_below_threshold\n",
      "0        x2        x3               False\n",
      "1        x1        x3               False\n",
      "2        x1        x2               False\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for method_name, method in methods_model_agnostic:\n",
    "\n",
    "    print(f\"\\n\\nMethod: {method_name}\")\n",
    "    df = result.loc[(result[\"model\"] == \"linear\") & (result[\"method\"] == method_name), \"ovo\"].iloc[0].copy()\n",
    "    df[\"is_below_threshold\"] = np.abs(df[method.method]) < THRESHOLD\n",
    "    print(df[[\"Feature 1\", \"Feature 2\", \"is_below_threshold\"]])\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, `Sejong Oh Performance Based Interaction` falsely detects interactions in the linear model. It suggests its high limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Method: Friedman H-statistic Interaction Measure\n",
      "  Feature 1 Feature 2  Friedman H-statistic Interaction Measure\n",
      "0        x1        x2                                  0.071313\n",
      "1        x2        x3                                  0.021479\n",
      "2        x1        x3                                  0.003483\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Method: Friedman H-statistic Interaction Measure NO_NORMALIZATION\n",
      "  Feature 1 Feature 2  Friedman H-statistic Interaction Measure\n",
      "0        x1        x2                                 55.933378\n",
      "1        x2        x3                                 52.130086\n",
      "2        x1        x3                                 17.138675\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Method: Greenwell Variable Interaction Measure\n",
      "  Feature 1 Feature 2  Greenwell Variable Interaction Measure\n",
      "0        x1        x2                                5.236567\n",
      "1        x2        x3                                3.238968\n",
      "2        x1        x3                                1.102311\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Method: Sejong Oh Performance Based Interaction Measure\n",
      "  Feature 1 Feature 2  Sejong Oh Performance Based Interaction Measure\n",
      "0        x2        x3                                        14.573852\n",
      "1        x1        x2                                         8.237627\n",
      "2        x1        x3                                         5.815884\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for method_name, _ in methods_model_agnostic:\n",
    "\n",
    "    print(f\"\\n\\nMethod: {method_name}\")\n",
    "    df = result.loc[(result[\"model\"] == \"random_forest\") & (result[\"method\"] == method_name), \"ovo\"].iloc[0].copy()\n",
    "    print(df)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of ` RandomForest`, both `Friedman H-statistic` (both normalized and un-normalized) and `Greenwell Variable interaction` seem to correctly capture `x1 - x2` non-additive influence (interaction). Again, `Sejong Oh Performance Based Interaction` falsely claims that `x1 - x3` interaction is the strongest. This suggests it's high limitations to correctly detect feature interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Method: Friedman H-statistic Interaction Measure\n",
      "  Feature 1 Feature 2  Friedman H-statistic Interaction Measure\n",
      "0        x1        x2                                  0.324242\n",
      "1        x2        x3                                  0.000643\n",
      "2        x1        x3                                  0.000391\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Method: Friedman H-statistic Interaction Measure NO_NORMALIZATION\n",
      "  Feature 1 Feature 2  Friedman H-statistic Interaction Measure\n",
      "0        x1        x2                                156.501917\n",
      "1        x2        x3                                  9.275499\n",
      "2        x1        x3                                  5.769737\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Method: Greenwell Variable Interaction Measure\n",
      "  Feature 1 Feature 2  Greenwell Variable Interaction Measure\n",
      "0        x1        x2                               11.735159\n",
      "1        x2        x3                                0.474459\n",
      "2        x1        x3                                0.429746\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Method: Sejong Oh Performance Based Interaction Measure\n",
      "  Feature 1 Feature 2  Sejong Oh Performance Based Interaction Measure\n",
      "0        x1        x2                                        20.017840\n",
      "1        x2        x3                                        16.320690\n",
      "2        x1        x3                                        14.765748\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for method_name, _ in methods_model_agnostic:\n",
    "\n",
    "    print(f\"\\n\\nMethod: {method_name}\")\n",
    "    df = result.loc[(result[\"model\"] == \"neural_network\") & (result[\"method\"] == method_name), \"ovo\"].iloc[0].copy()\n",
    "    print(df)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of `MLP`, all of the methods correctly capture `x1 - x2` as the highest interaction. `Friedman H-statistic` (normalized and un-normalized) and `Greenwell Variable interaction` values are negligible for pairs different to the actual interaction (`x1 - x2`). It may suggest their capability to correctly capture feature interactions. For well-performing model such as `MLP`, performance-based `Sejong Oh Performance Based Interaction` correctly indicates `x1 - x2` as the most relevant. This may suggest, that for well-performing models such as neural networks, performance-based methods may produce good results. Nevertheless, non-existing interaction values between `x1 - x3` and `x2 - x3` have high interaction values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "additivity_meter = AdditivityMeter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.05it/s]\n"
     ]
    }
   ],
   "source": [
    "additivity = list()\n",
    "for name_model, model in tqdm(models):\n",
    "    additivity_meter.fit(model, X)\n",
    "    additivity.append({\"model\": name_model, \"additivity\": additivity_meter.additivity_index})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "            model  additivity\n0          linear    1.000000\n1   random_forest    0.919103\n2  neural_network    0.848242",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>additivity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>linear</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>random_forest</td>\n      <td>0.919103</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>neural_network</td>\n      <td>0.848242</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_records(additivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the more complex the model is, the less additive nature it has (with linear model having perfect 1.0 additivity). This measure clearly depicts how much variance in each model is explained by interactions between features."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, let's consider the potential impact of the feature interaction detection on the performance of the analysed models. Let's assume that using feature interaction methods we improved our understanding of the underlying problem and  discovered the interaction between `x1 - x2` features."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "mse = lambda x, y : (np.square(x - y)).mean(axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "            model  MSE - test\n0          linear  237.419422\n1   random_forest  237.510393\n2  neural_network  211.775486",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>MSE - test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>linear</td>\n      <td>237.419422</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>random_forest</td>\n      <td>237.510393</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>neural_network</td>\n      <td>211.775486</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_baseline = pd.DataFrame.from_records([{\"model\": name, \"MSE - test\": mse(model.predict(X_test), y_test)} for name, model in models])\n",
    "performance_baseline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, as a part of feature engineering process, let's add the detected interaction as a new feature."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "          x1        x2        x3      x1*x2\n0   2.641982  4.958331  0.415673  13.099821\n1   3.756013  4.882720 -3.728535  18.339557\n2   4.471999 -2.991423  3.290477 -13.377639\n3   2.719406 -3.616683  4.003583  -9.835229\n4  -1.955196 -0.266347  2.312092   0.520762\n..       ...       ...       ...        ...\n95  0.963227 -0.788743 -2.421366  -0.759739\n96 -2.270747  3.886262 -2.485458  -8.824719\n97 -3.611987 -0.183632  0.092415   0.663278\n98  4.538158  3.448407  3.972457  15.649413\n99  1.438592 -1.602360  3.765470  -2.305142\n\n[100 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>x3</th>\n      <th>x1*x2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.641982</td>\n      <td>4.958331</td>\n      <td>0.415673</td>\n      <td>13.099821</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.756013</td>\n      <td>4.882720</td>\n      <td>-3.728535</td>\n      <td>18.339557</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.471999</td>\n      <td>-2.991423</td>\n      <td>3.290477</td>\n      <td>-13.377639</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.719406</td>\n      <td>-3.616683</td>\n      <td>4.003583</td>\n      <td>-9.835229</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.955196</td>\n      <td>-0.266347</td>\n      <td>2.312092</td>\n      <td>0.520762</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0.963227</td>\n      <td>-0.788743</td>\n      <td>-2.421366</td>\n      <td>-0.759739</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>-2.270747</td>\n      <td>3.886262</td>\n      <td>-2.485458</td>\n      <td>-8.824719</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>-3.611987</td>\n      <td>-0.183632</td>\n      <td>0.092415</td>\n      <td>0.663278</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>4.538158</td>\n      <td>3.448407</td>\n      <td>3.972457</td>\n      <td>15.649413</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>1.438592</td>\n      <td>-1.602360</td>\n      <td>3.765470</td>\n      <td>-2.305142</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_interaction_detected = X.copy()\n",
    "X_interaction_detected[\"x1*x2\"] = X_interaction_detected.apply(lambda row: row[\"x1\"] * row[\"x2\"], axis=1)\n",
    "X_interaction_detected"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "X_train_int, X_test_int, y_train_int, y_test_int = train_test_split(X_interaction_detected, y, test_size=0.3, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "models_int = [(\"linear\", LinearRegression()), (\"random_forest\", RandomForestRegressor()), (\"neural_network\", MLPRegressor(hidden_layer_sizes=(5, 2), max_iter=30000))]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pawel_fijalkowski/Praca inżynierska/feature-interactions-explanations/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for _, model in models_int:\n",
    "    model.fit(X_train_int, y_train_int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "            model  MSE - test\n0          linear    0.102788\n1   random_forest  175.344798\n2  neural_network  196.763444",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>MSE - test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>linear</td>\n      <td>0.102788</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>random_forest</td>\n      <td>175.344798</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>neural_network</td>\n      <td>196.763444</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_interaction = pd.DataFrame.from_records([{\"model\": name, \"MSE - test\": mse(model.predict(X_test_int), y_test_int)} for name, model in models_int])\n",
    "performance_interaction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comparing `performance_baseline` and `performance_interaction`, we can clearly see that adding detected interaction to the data significantly improved the performance of all the models. Of course, in this case target (`y`) becomes linear function of the features and so `MSE` of the `linear` model is close to zero. It suggests that discovering interaction in the data not only improves the understanding and explainability of the model/problem, but also may improve the model performance.\n",
    "\n",
    "Above example raises important question about how in real life scenario should the `artemis` user know what function best represents the interaction between pair of features. In our case, data was generated from the known model, and so we know that non-additivity is captured within multiplication operation between `x1` and `x2`. Currently, automatic function search is not implemented, but creating such a functionality and combining it with `artemis` lays foundation for future work."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
